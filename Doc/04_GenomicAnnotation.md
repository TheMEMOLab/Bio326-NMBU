# Prokaryotic functional genome annotation

### So far have obtained indiviual metagenome assembled genomes (MAGs) from the rummen metagenome. Let's review our workflow to see what is the next step: 

![workflow](https://github.com/avera1988/NMBU-Bio-326/blob/main/images/wrokflowmetagenome.png) 

After binning with [MetaBat2](https://bitbucket.org/berkeleylab/metabat/src/master/) we obtained 9 bins. We used [CheckM](https://ecogenomics.github.io/CheckM/) to asses the quality of these MAGs.

Metabat2 produce a set of bins as the following example:

```bash
ls -1|grep .fa|sort -V
bin.1.fa
bin.2.fa
bin.3.fa
bin.4.fa
bin.5.fa
bin.6.fa
bin.7.fa
bin.8.fa
bin.9.fa
bin.10.fa
bin.11.fa
bin.12.fa
bin.13.fa
bin.14.fa
bin.15.fa
bin.16.fa
bin.17.fa
bin.18.fa
bin.19.fa
bin.20.fa
bin.21.fa
bin.22.fa
bin.23.fa
bin.24.fa
bin.25.fa
bin.26.fa
```
We then can use the report from the ```assemblycomparator2``` to check the quality report by CheckM. We can use either the report table or directly the checkM results 

Let's go to the ```cd results_ac2/``` folder and enter the checkM results

```console
$ ls results_ac2/checkm2/
checkm2.log  diamond_output  protein_files  quality_report.tsv
$ more results_ac2/checkm2/quality_report.tsv
Name    Completeness    Contamination   Completeness_Model_Used Translation_Table_Used  Coding_Density  Contig_N50      Aver
age_Gene_Length Genome_Size     GC_Content      Total_Coding_Sequences  Additional_Notes
bin.1   65.29   12.04   Gradient Boost (General Model)  11      0.824   61619   223.82011834319528      1368180 0.54    1690
        None
bin.10  88.2    20.77   Neural Network (Specific Model) 11      0.887   125057  296.9914163090129       2335282 0.33    2330
        None
bin.11  93.91   63.86   Gradient Boost (General Model)  11      0.848   27951   224.5304107844178       7434991 0.5     9421
        Low confidence prediction - substantial (34%) disagreement between completeness prediction models
bin.12  50.41   31.62   Neural Network (Specific Model) 11      0.735   29328   192.14297589359933      2814547 0.31    3609
        None
bin.13  67.87   3.91    Neural Network (Specific Model) 11      0.9     1187215 276.24345364472754      1298639 0.37    1413
        None
```

Now can start filtering the MAGs. A good criterion is to use the quality and contamination of the MAGs to sort them into *High*, *Medium* and *Low* quality MAGs. 
We can use the following table from [Bowers et al.,](https://www.nature.com/articles/nbt.3893) to classify the MAGs:
![tablemags](https://github.com/avera1988/NMBU-Bio-326/blob/main/images/mags.jpg)

We have all this information from the table generated by checkm, and we can use it to extract these quality score parameters. We can easily pick manually those "good quality" MAGs and sorted them for quality and contamination scores. Let's say >= 70 % completeness and =< 10 % contamination by looking into this table and applying some conditional using awk:

```bash
cat results_ac2/checkm2/quality_report.tsv | awk '{if($2 > 70 && $3 < 10) print $1"\t"$2"\t"$3}'
rumen.3 94.14   7.56
rumen.6 72.12   1.12
```
**We can see here that only 2 bins meet the condition of > 70 % completeness and < 10 % contamination.**

Then let's look for the taxonomy of those particularly bins using the gtdbtk results:

```bash
cat results_ac2/checkm2/quality_report.tsv | awk '{if($2 > 70 && $3 < 10) print $1}'|sed 's/.f
a//g'|fgrep -f - results_ac2/gtdbtk/gtdbtk.summary.tsv |cut -f 1,2
rumen.3 d__Archaea;p__Methanobacteriota;c__Methanobacteria;o__Methanobacteriales;f__Methanobacteriaceae;g__Methanobrevibacter_A;s__Methanobrevibacter_A sp900313645
rumen.6 d__Bacteria;p__Bacteroidota;c__Bacteroidia;o__Bacteroidales;f__Bacteroidaceae;g__Prevotella;s__Prevotella sp900316295
```

**Our bins were classified as an Archea *Metanobrevibacter* and a bacteria *Prevotella*.**

We can then predict genes and annotate this by comparing with public databases. For doing this we will use DRAM...

## DRAM: Distilled and Refined Annotation of Metabolism

**"[DRAM](https://github.com/WrightonLabCSU/DRAM) (Distilled and Refined Annotation of Metabolism) is a tool for annotating metagenomic assembled genomes and VirSorter identified viral contigs. DRAM annotates MAGs and viral contigs using KEGG (if provided by the user), UniRef90, PFAM, dbCAN, RefSeq viral, VOGDB and the MEROPS peptidase database as well as custom user databases..."**
 ![dramaanot](https://github.com/avera1988/NMBU-Bio-326/blob/main/images/DRAM.jpg)

To use DRAM we first need to create a directory and place there those bins we selected by completeness and contamination scoring (in this example rumen.3 and rumen.6). These bins are int he metabat2 results folder so let's create a new folder in the ```$SCRATCH/prok/results``` named ```bins_for_dram``` and move there those selected bins:

```bash

$ mkdir $SCRATCH/prok/results/bins_for_dram
$ cp $SCRATCH/prok/results/metabat2/rumen.3.fa bins_for_dram/
$ cp $SCRATCH/prok/results/metabat2/rumen.3.fa bins_for_dram/rumen.6.fa

```

Let's check these files were copied:

```bash
$ ls $SCRATCH/prok/results/bins_for_dram/
rumen.3.fa  rumen.6.fa
```

With this we can run DRAM using the following ```sbatch``` script:

```bash

#!/bin/bash

###############SLURM SCRIPT###################################

## Job name:
#SBATCH --job-name=DRAM
#
## Wall time limit:
#SBATCH --time=48:00:00
#
## Other parameters:
#SBATCH --cpus-per-task 10
#SBATCH --mem=80G
#SBATCH -p hugemem
#SBATCH -o slurm-%x-%A.out

###########################################################

## Set up job environment:

module --quiet purge  # Reset the modules to the system default
module load Miniconda3 && eval "$(conda shell.bash hook)"

##Activate conda environments
conda activate /mnt/users/auve/mycondaenvs/DRAM

##Declaring variables: These needs to be passed as arguments in the command line

magsdir=$1 #Directory with the MAG e.g /mnt/SCRATCH/auve/DRAM_Test/BinsForDram
ext=$2 #Extension of the MAGs e.g. .fa
outdir=$3 #output directory e.f /mnt/SCRATCH/auve/DRAM_Test/
####Do some work:########

## For debuggin
echo "Hello" $USER
echo "my submit directory is:"
echo $SLURM_SUBMIT_DIR
echo "this is the job:"
echo $SLURM_JOB_ID
echo "I am running on:"
echo $SLURM_NODELIST
echo "I am running with:"
echo $SLURM_CPUS_ON_NODE "cpus"
echo "Today is:"
date


## Copying data to local node for faster computation

cd $TMPDIR

#Check if $USER exists in $TMPDIR

if [[ -d $USER ]]
        then
                echo "$USER exists on $TMPDIR"
        else
                mkdir $USER
fi

cd $USER
mkdir tmpDir_of.$SLURM_JOB_ID
cd tmpDir_of.$SLURM_JOB_ID
wd=$(pwd)

#Copy the MAGs to the $TMPDIR

echo "copying MAGs to" $TMPDIR/$USER/tmpDir_of.$SLURM_JOB_ID.$input
mkdir MAGS && cd MAGS
cp -r $magsdir/*$ext .
cd $wd

##################DRAM##############################

echo "DRAM started at"
date

DRAM.py annotate \
-i 'MAGS/*.'$ext \
-o dram.annotation \
--threads $SLURM_CPUS_ON_NODE

echo "Distilling..."

DRAM.py distill \
-i dram.annotation/annotations.tsv \
-o dram.genome_summaries \
--trna_path dram.annotation/trnas.tsv \
--rrna_path dram.annotation/rrnas.tsv

echo "DRAM finished at"
date


mkdir DRAM.Results.dir
mv dram.annotation DRAM.Results.dir
mv dram.genome_summaries DRAM.Results.dir

cp -r DRAM.Results.dir $outdir

echo "DRAM results are in: " $outdir/DRAM.Resulits.dir

##Clean TMPDIR

cd $TMPDIR/$USER
rm -r $wd

##

echo "I've done...Bye!"
```

**A copy of this script is at:**

```/mnt/courses/BIO326/PROK/scripts/dram.SLURM.sh```

For running this script, we need to provide in the same command line 3 arguments:
- absoulte path of our input directory ```$SCRATCH/prok/results/bins_for_dram```
- The extension of our fasta files ```fa```
- The output directory ```SCRATCH/prok/results/```

Let's run the script ```dram.SLURM.sh```

```bash
$ sbatch dram.SLURM.sh $SCRATCH/prok/results/bins_for_dram fa $SCRATCH/prok/results
```

** !NB DRAM will take around 3-8 hrs for running and requires a lot of memory **

When DRAM finishes it will produce the following directory:

```DRAM.Results.dir```

We can then take a look:

```bash
$ cd $SCRATCH/prok/results/DRAM.Results.dir
$ ls
dram.annotation  dram.genome_summaries
```
There are two directories: 
* dram.annotation.dir: It has all the "raw" annotations, gene sequeces, protein preditions of the MAG's
* dram.genome_summaries.dir: It has the destilled part of the genomes with the sorted metabolic functions.

Let's check the annotation directory:

```
$ ls
annotations.tsv  genbank  genes.faa  genes.fna  genes.gff  rrnas.tsv  scaffolds.fna  trnas.tsv
```

Here we can find a table with annotations (annotations.tsv) as well as 3 fasta files:

- genes.fna (All the predicted coding genes as nucleotides)
- genes.faa (All the predicted coding genes translated to proteins)
- sacaffolds.fna (The total scaffolds/contigs of the bins)

Then take a look into the summaries directory:

```bash
cd $SCRATCH/prok/results/DRAM.Results.dir/dram.genome_summaries
$ ls
genome_stats.tsv  metabolism_summary.xlsx  product.html  product.tsv
```
The files have different information:

* genome_stats.tsv: Basic annotaion stats of the genomes, as # of contigs/scaffolds, taxonomy, RNAgenes etc.
* metabolism_summary.xlsx: An excel file with all the Metabolic summary in each genome.
* product.html: Interactive heatmaps of the metabolic summaries
* product.tsv: Tables to reproduce the heatmaps of above

Although we can display the content of the *.tsv* files obtainded by DRAM here in the terminal, the  metabolism_summary.xlsx and product.html files are visually friendly, so it is recommendable to export these data to our personal computers and take a look. 

Once in your computer, you can open the product.html, to explore the metabolic potential of your MAGs.

![dramhtml](https://github.com/TheMEMOLab/Bio326-NMBU/blob/main/images/visualizationDRAM.png)

is there any special metabolic pathway would you like to look at? 

Now is time for the funny part that is parsing the information and to interpret the biological meaning encoding in these MAGs ...

### Enjoy DRAM and have fun looking through your annotated MAGs